[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Quarto Website Notes!",
    "section": "",
    "text": "Creating a Function Website that actually makes the URL Work!\n\nBuild\nCommit\nPush\n\nAdding Images\n\ndownload image\nin doc YAML\n\ndo “resources:”,\nindent then “- image/file/path/image.jpeg”\n\nreference image in doc with\n\n![](image.jpeg)"
  },
  {
    "objectID": "CS263Project/index.html",
    "href": "CS263Project/index.html",
    "title": "Ethical Issues in Remote Sensing",
    "section": "",
    "text": "Remote sensing is the use of satellites or low flying air crafts to scan the earth in order to obtain geographic information about the area. This data is then stored in digital images, which then can be used with image processing techniques to detect and “sense” specific things in the environment of the image.\nThis is done by measuring the reflected and emitted radiation from the physical characteristics of the landscape at a distance. Low Earth Orbit (LEO) Satellites are a common system used to do remote sensing, see the Common Questions page to learn more about different types of remote sensing systems."
  },
  {
    "objectID": "CS263Project/index.html#what-is-remote-sensing",
    "href": "CS263Project/index.html#what-is-remote-sensing",
    "title": "Ethical Issues in Remote Sensing",
    "section": "",
    "text": "Remote sensing is the use of satellites or low flying air crafts to scan the earth in order to obtain geographic information about the area. This data is then stored in digital images, which then can be used with image processing techniques to detect and “sense” specific things in the environment of the image.\nThis is done by measuring the reflected and emitted radiation from the physical characteristics of the landscape at a distance. Low Earth Orbit (LEO) Satellites are a common system used to do remote sensing, see the Common Questions page to learn more about different types of remote sensing systems."
  },
  {
    "objectID": "CS263Project/index.html#what-is-artificial-intelligence",
    "href": "CS263Project/index.html#what-is-artificial-intelligence",
    "title": "Ethical Issues in Remote Sensing",
    "section": "What is artificial intelligence?",
    "text": "What is artificial intelligence?\nArtificial Intelligence is technology that allows machines and computers to perform tasks such as problem solving, decision making, comprehension and creativity to simulate human learning.\nThere are many different types of artificial intelligence but the one that is most commonly used within remote sensing is machine learning. Machine learning is the ability to use and develop methods to learn and adapt in order to perform tasks without specific instructions."
  },
  {
    "objectID": "CS263Project/index.html#artificial-intelligence-in-remote-sensing",
    "href": "CS263Project/index.html#artificial-intelligence-in-remote-sensing",
    "title": "Ethical Issues in Remote Sensing",
    "section": "Artificial Intelligence in Remote Sensing",
    "text": "Artificial Intelligence in Remote Sensing\nMachine learning is used in remote sensing to analyze the large amounts of spatial data that is produced. It can be used for:\n\nImage Classification\nObject Detection\nPattern Recognition\nFeature Extraction\nData Fusion\n\nLearn more about these different uses of AI in Remote Sensing on the Common Questions page."
  },
  {
    "objectID": "CS263Project/tabs/Resources.html",
    "href": "CS263Project/tabs/Resources.html",
    "title": "Resources",
    "section": "",
    "text": "Picture Sources\n“Optical Remote Sensing.” Centre for Remote Imaging, Sensing and Processing (CRISP), National University of Singapore.\n“InSAR: Satellite-Based Technique Captures Overall Deformation Picture.” U.S. Geological Survey (USGS).\n“LiDAR vs Photogrammetry: Key Differences and Applications.” YellowScan.\n“MODIS Platforms.” NASA GSFC: Atmosphere Imager.\n“Example Image of NOAA’s Lake Erie HAB Tracker.” ResearchGate.\n“Landsat Missions.” ESA Earth Online, European Space Agency.\n“What Are the Different Types of Sensors Used in UAV Remote Sensing?” LinkedIn Pulse.\n\n\nCase Study Sources\n“HABs and Hypoxia.” NOAA Great Lakes Environmental Research Laboratory.\n“Wildfire and Ecosystem Resilience Risk Assessment.” California Natural Resources Agency.\n“Regional-Scale Hydrological Monitoring of Wetlands with Sentinel-1 InSAR.” NASA Earth Science Division Publications.\nMüller, Karen, et al. “The Role of Satellite Remote Sensing in Marine Pollution Monitoring.” Marine Pollution Bulletin, vol. 137, 2018, pp. 519–530.\n“Lasers and Satellites Help Us Map and Restore the Chesapeake Watershed.” Chesapeake Bay Program.\n“Remote Sensing.” Geophysical Institute, University of Alaska Fairbanks.\n“Confronting the Great Salt Lake’s Dust Dilemmas.” Utah Division of Water Resources.\n\n\nGeneral Information Sources\n“What Is Remote Sensing and What Is It Used For?” U.S. Geological Survey (USGS)\n“Artificial Intelligence.” IBM Think.\n“What Is the Landsat Satellite Program and Why Is It Important?” U.S. Geological Survey (USGS).\n“Sentinel-2.” European Space Agency (ESA).\nBermudez, Marc, et al. “UAV-Based Remote Sensing: A Centimeter or Millimeter Resolution Revolution.” Drones, vol. 7, no. 6, 2023.\n“AI Object Detection.” Datenwissen.\n“Neural Network Pattern Recognition.” Viso Suite.\n“Image Classification in Computer Vision.” Viso Suite.\n“Feature Extraction.” IBM Think."
  },
  {
    "objectID": "CS263Project/tabs/EthicalIssues.html",
    "href": "CS263Project/tabs/EthicalIssues.html",
    "title": "Ethcial Issues",
    "section": "",
    "text": "There are many ethical issues to consider when talking about remote sensing. These are important to consider because there is very little public conversation about what remote sensing is. It is not an issue that is brushed under the table but it is not something that is widely discussed.\n\nPrivacy and Surveillance:\n\nUnconsented observation:\nRemote sensing can capture data about individuals, communities, or private properties without their knowledge or consent.\n\n\nMass surveillance:\nGovernments or companies might use remote sensing for population monitoring or political control, raising civil liberty concerns.\n\n\n\nInformed Consent:\nOften, people or communities being observed are unaware that data is being collected about them, which violates the ethical principle of informed consent.\n\n\nData Misuse:\n\nMilitary or political exploitation:\nRemote sensing data can be used for targeting in conflicts or for espionage.\n\n\nCommercial exploitation:\nCompanies may sell or use satellite imagery to exploit natural resources or real estate without local stakeholder involvement.\n\n\n\nBias and Representation:\nData interpretation can be biased, especially when used to inform policies affecting vulnerable communities. Remote sensing may overlook cultural or social contexts, leading to technocratic or top-down decisions that ignore local knowledge.\n\n\nEnvironmental and Social Impact:\nDrone usage may disrupt wildlife or intrude on indigenous lands. Decisions based on remote sensing (e.g., for urban planning, disaster relief) may inadvertently marginalize already disadvantaged populations.\n\n\nData Ownership and Access:\nWho owns the data? Satellite imagery is often controlled by governments or private corporations, limiting transparency and equitable access for affected communities."
  },
  {
    "objectID": "tabs/salmon_tummys.html",
    "href": "tabs/salmon_tummys.html",
    "title": "Diets of Juvenile Chinhook Salmon in PNW",
    "section": "",
    "text": "In Washington State, salmon are a big part of the water’s ecosystems and provide jobs and food to many people and animals. In elementary school most students spend time learning about the salmon cycle, even getting to raise their own fish. For this project we wanted to focus on something that was both interesting to us and held a bit of importance to our beloved home. Both of us were also intrigued by the prospect of this being someone’s job, going out and collecting this data. Over the course of this project we looked at the many different kinds of food that these juvenile chinhook salmon ate, how big they were,where these fish came from, and comparing the fish from hatcheries in various parts of the Pacific Northwest to the fish that were born in the wild. We examined the correlatory differences in the prey from both these sets of fish and the size of these fish.\n\n\n\nJuvenile Chinook salmon, Roger Tabor/USFWS, Public Domain, https://www.fws.gov/media/juvenile-chinook-salmon"
  },
  {
    "objectID": "tabs/salmon_tummys.html#weight-of-fish-and-prey-type",
    "href": "tabs/salmon_tummys.html#weight-of-fish-and-prey-type",
    "title": "Diets of Juvenile Chinhook Salmon in PNW",
    "section": "Weight of Fish and Prey Type",
    "text": "Weight of Fish and Prey Type\nIn this second graph we are exploring how the weight of a salmon correlates with the type of food it eats.\n\n\n\n\n\n\n\n\n\nThe fact that some of the heaviest fish ate plankton could be surprising, especially after cephalopods, a much more likely high median, is just above.\nThis graph is much like the previous one with all the same axes, though now the boxplots are split by fish that were raised in hatcheries vs. those in the wild.\n\n\n\n\n\n\n\n\n\nInterestingly, there is a strong correlation of wild fish being the heavier on average in all categories, and the hatchery raised median weights are much lighter, and nearly identical (~25 grams) across all categories, implying much more homogeneity in their group."
  },
  {
    "objectID": "tabs/salmon_tummys.html#length-of-fish-and-prey-type",
    "href": "tabs/salmon_tummys.html#length-of-fish-and-prey-type",
    "title": "Diets of Juvenile Chinhook Salmon in PNW",
    "section": "Length of Fish and Prey Type",
    "text": "Length of Fish and Prey Type\nFor our last size based graph we wanted to explore the length of the fish with how they correlate to the prey type eaten as compared to the weight graphs above. We also wanted to explore a graph with much more complication, and analyze it on many levels.\n\n\n\n\n\n\n\n\n\nThere’s a lot going on in this graph, but also some pretty interesting takeaways. The overall boxplots show that length has the same correlation with prey type as weight. The light gray beeswarm dots show that the hatchery fish once again are shorter than the whole group. Finally, the colored dots show the longest fish grouped by each hatchery."
  },
  {
    "objectID": "tabs/miniproj2.html",
    "href": "tabs/miniproj2.html",
    "title": "Mini Project #2",
    "section": "",
    "text": "After doing our amazing research on salmon we wanted to look at more data from Washington, and one thing that is becoming very prevalent is wildfires, both of us have been in very close proximity to wildfires and have seen the aftermath of many of them. We want to look at the amount of forest land that was lost or affected by forest fires. Thinking through this data we quickly found a data set of the land area affected by fires, we then realized that it would be interesting to see the amount of forested area that was affected by the fires and then also the total land area that was affected in the county as a whole."
  },
  {
    "objectID": "tabs/miniproj2.html#motivations-behind-our-data",
    "href": "tabs/miniproj2.html#motivations-behind-our-data",
    "title": "Mini Project #2",
    "section": "",
    "text": "After doing our amazing research on salmon we wanted to look at more data from Washington, and one thing that is becoming very prevalent is wildfires, both of us have been in very close proximity to wildfires and have seen the aftermath of many of them. We want to look at the amount of forest land that was lost or affected by forest fires. Thinking through this data we quickly found a data set of the land area affected by fires, we then realized that it would be interesting to see the amount of forested area that was affected by the fires and then also the total land area that was affected in the county as a whole."
  },
  {
    "objectID": "tabs/miniproj2.html#research-questions",
    "href": "tabs/miniproj2.html#research-questions",
    "title": "Mini Project #2",
    "section": "Research Questions",
    "text": "Research Questions\nWe are interested in looking at the total land area that is affected by forest fires in our home state. We wanted to not only look at the forest land that was effected by also the amount of land area that is forested and then also affected by the fire.\n\n# Our first table came from wikipedia, which is an allowed source\nis_valid_robotstxt(\"https://en.wikipedia.org/wiki/List_of_Washington_wildfires\")\n\n[1] TRUE\n\n#reading the html of the website\nwildfires &lt;- read_html(\"https://en.wikipedia.org/wiki/List_of_Washington_wildfires\")\n\n#scraping the table\nwildfiretables &lt;- html_nodes(wildfires, css = \"table\") \n\n\n#our first raw set of tables\ntables &lt;- (html_table(wildfiretables, header = TRUE, fill = TRUE))\n\nknitr::kable(head(tables))\n\n\n# Since we had so many tables from one scrape to use, we created a small \n# function to choose the table from the list using its subset number, cleaned \n# the names, remove unnecessary columns, and rename a common variables. Due to \n# inconsistency, all variables were set set as character and then parsed for \n# numbers.\n\ncleaninggg &lt;- function(table, i) {\n  html_table(table, header = TRUE, fill = TRUE)[[i]]|&gt; \n    janitor::clean_names() |&gt;\n    select(-notes, -image, -injuries, -complex_name) |&gt;\n    mutate(across(c(structureslost, size_acres), as.character),\n           across(c(structureslost, size_acres), parse_number)) |&gt;\n    rename(\"fire_size_acres\" = \"size_acres\")\n}\n\n# Running the function for each of the times to \n# pull the data out of the list from wikipedia into 5 (nearly) uniform datasets\ntwenty &lt;- cleaninggg(wildfiretables, 2) |&gt; rename(\"start_date\" = \"start_date_cause\")\nten &lt;- cleaninggg(wildfiretables, 3) \nthousand &lt;- cleaninggg(wildfiretables, 4)\nnines &lt;- cleaninggg(wildfiretables, 5) \nminors &lt;- cleaninggg(wildfiretables, 6) \n\n# Binds all of the major fires into one dataset and removes deaths for \n# consistency with the minor fires\nmajors &lt;- rbind(twenty, ten, thousand, nines) |&gt; select(-deaths)\n\n# Adds a column that identifies is a fire was major or minor\nminors['fire_type'] = \"Minor\"\nmajors['fire_type'] = \"Major\"\n\n# Joins all fires together\nfires &lt;- rbind(majors, minors)\n\nknitr::kable(head(fires))\n\n\n\n\n\n\n\n\n\n\n\n\n\nyear\nfire_name\ncounty\nstart_date\nfire_size_acres\nstructureslost\nfire_type\n\n\n\n\n2024\nBeam Road Fire[2]\nYakima\nJune 15\n8542\n0\nMajor\n\n\n2024\nBig Horn Fire[3][4]\nKlickitat\nJuly 22, unknown\n51569\n0\nMajor\n\n\n2024\nBlack Canyon Fire[5]\nYakima\nJuly 22, unknown\n9211\n0\nMajor\n\n\n2024\nCougar Creek Fire[6][7]\nAsotin & Garfield\nJuly 15, unknown\n20699\n4\nMajor\n\n\n2024\nPioneer Fire[8]\nChelan\nJune 8, human caused\n36763\n0\nMajor\n\n\n2024\nRetreat Fire[9][10]\nYakima\nJuly 23, cause unknown\n44588\n5\nMajor\n\n\n\n\n\n\n# As most major fires burn throughout forests, we wanted to add in a dataset \n# about forest coverage per county, we were planning to make a for-loop for \n# this, but all of the websites we tried to scrape weren't reading the actual \n# number as it was stored as an image? So we found this website that stores it\n# all as a list\nis_valid_robotstxt(\"https://data.workingforests.org/#\")\n\n[1] TRUE\n\nsession &lt;- bow(\"https://data.workingforests.org/#\")\n\n# Scraped the county names as one list\ncounty_title &lt;- scrape(session) |&gt;\n  html_nodes(\".countyName\") |&gt;\n  html_text()\nknitr::kable(head(county_title))\n\n\n\n\nx\n\n\n\n\nStatewide\n\n\nAdams County\n\n\nAsotin County\n\n\nBenton County\n\n\nChelan County\n\n\nClallam County\n\n\n\n\n# Scraped the forest coverage as another list\nforest_cov &lt;- scrape(session) |&gt;\n  html_nodes(\".dataValueEmphasized\") |&gt;\n  html_text() \nknitr::kable(head(forest_cov))\n\n\n\n\nx\n\n\n\n\n22,983,438\n\n\n1,452\n\n\n103,022\n\n\n351\n\n\n1,392,891\n\n\n1,034,606\n\n\n\n\n# Brought the 2 lists together as one tibble with 2 columns, removed \" County\"\n# from name to synchronize with main table\nforest_cover &lt;- tibble(county = county_title, \n                    forest_coverage_acres = forest_cov) |&gt;\n  mutate(county = str_remove(county, \" County\"),\n         forest_coverage_acres = parse_number(forest_coverage_acres))\n\n# Joins this forest coverage with our fire data by county. For ease of analysis\n# at this stage without knowing string analysis in detail (yet!), we removed all\n# rows that contained 2 counties by dropping NA's in forest coverage. This way \n# all rows should have a complete collection of county name, forest size, and \n# fire size. \nfullfires &lt;- fires |&gt; left_join(forest_cover) |&gt;\n  drop_na(forest_coverage_acres) \n\nknitr::kable(head(fullfires))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nyear\nfire_name\ncounty\nstart_date\nfire_size_acres\nstructureslost\nfire_type\nforest_coverage_acres\n\n\n\n\n2024\nBeam Road Fire[2]\nYakima\nJune 15\n8542\n0\nMajor\n1201021\n\n\n2024\nBig Horn Fire[3][4]\nKlickitat\nJuly 22, unknown\n51569\n0\nMajor\n516397\n\n\n2024\nBlack Canyon Fire[5]\nYakima\nJuly 22, unknown\n9211\n0\nMajor\n1201021\n\n\n2024\nPioneer Fire[8]\nChelan\nJune 8, human caused\n36763\n0\nMajor\n1392891\n\n\n2024\nRetreat Fire[9][10]\nYakima\nJuly 23, cause unknown\n44588\n5\nMajor\n1201021\n\n\n2023\nGray Fire[15]\nSpokane\n\n10085\n259\nMajor\n318506\n\n\n\n\n\n\n# Lastly, we also thought it would be good to include the size of the counties \n# themselves as a comparison to the size of the forest its fires, so we scraped \n# this table\ncounties &lt;- read_html(\"https://en.wikipedia.org/wiki/List_of_counties_in_Washington\")\ncountytable &lt;- html_nodes(counties, css = \"table\") \n\n# This identifies the table we want, cleans the names, removes part of the name\n# ' County' for consistency, parses the sq. mi. and converts it to acres, and\n# selects just county and county size\n\ncountysize &lt;- html_table(countytable, header = TRUE, fill = TRUE)[[2]] |&gt; \n  janitor::clean_names() |&gt;\n  mutate(county = str_remove(county, \" County\"),\n         county_size_acres = parse_number(land_area_11) * 640) |&gt;\n    select(county, county_size_acres)\n\n# Finally ! We join this last table with the main dataset\nfinal_fires &lt;- fullfires |&gt; left_join(countysize)\n\nknitr::kable(head(final_fires))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nyear\nfire_name\ncounty\nstart_date\nfire_size_acres\nstructureslost\nfire_type\nforest_coverage_acres\ncounty_size_acres\n\n\n\n\n2024\nBeam Road Fire[2]\nYakima\nJune 15\n8542\n0\nMajor\n1201021\n2749440\n\n\n2024\nBig Horn Fire[3][4]\nKlickitat\nJuly 22, unknown\n51569\n0\nMajor\n516397\n1198080\n\n\n2024\nBlack Canyon Fire[5]\nYakima\nJuly 22, unknown\n9211\n0\nMajor\n1201021\n2749440\n\n\n2024\nPioneer Fire[8]\nChelan\nJune 8, human caused\n36763\n0\nMajor\n1392891\n1868800\n\n\n2024\nRetreat Fire[9][10]\nYakima\nJuly 23, cause unknown\n44588\n5\nMajor\n1201021\n2749440\n\n\n2023\nGray Fire[15]\nSpokane\n\n10085\n259\nMajor\n318506\n1128960"
  },
  {
    "objectID": "tabs/miniproj2.html#future-uses-of-this-data",
    "href": "tabs/miniproj2.html#future-uses-of-this-data",
    "title": "Mini Project #2",
    "section": "Future Uses of this Data",
    "text": "Future Uses of this Data\nFor future uses of this data we have a lot of things that we want to clean with string functions. We were also looking into census data for each county in Washington, which would be interesting to see if there is higher population in a county that has more forest fire activity. It would also be interesting to add spatial data to this to map the percentage of forest area affected by fires or other percentage maps."
  },
  {
    "objectID": "tabs/miniproj1.html",
    "href": "tabs/miniproj1.html",
    "title": "Mini Project #1",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dplyr)\nlibrary(sf)\nlibrary(tmap)\nlibrary(maps)\nlibrary(viridis)\nlibrary(htmltools)\nlibrary(glue)\nlibrary(leaflet)\n\nus_states &lt;- map_data(\"state\")\n\nfrogs &lt;- read.csv(\"~/Desktop/15/SDS264/data/most_common_frog.csv\") |&gt;\n  na.omit()\n\nforests &lt;- read.csv(\"~/Desktop/15/SDS264/data/forests.csv\") |&gt;\n  mutate('forest_cover' = forest_area/land_area * 100)\n\nstates &lt;- read_sf(\"https://rstudio.github.io/leaflet/json/us-states.geojson\")"
  },
  {
    "objectID": "tabs/miniproj1.html#importing-data",
    "href": "tabs/miniproj1.html#importing-data",
    "title": "Mini Project #1",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dplyr)\nlibrary(sf)\nlibrary(tmap)\nlibrary(maps)\nlibrary(viridis)\nlibrary(htmltools)\nlibrary(glue)\nlibrary(leaflet)\n\nus_states &lt;- map_data(\"state\")\n\nfrogs &lt;- read.csv(\"~/Desktop/15/SDS264/data/most_common_frog.csv\") |&gt;\n  na.omit()\n\nforests &lt;- read.csv(\"~/Desktop/15/SDS264/data/forests.csv\") |&gt;\n  mutate('forest_cover' = forest_area/land_area * 100)\n\nstates &lt;- read_sf(\"https://rstudio.github.io/leaflet/json/us-states.geojson\")"
  },
  {
    "objectID": "tabs/miniproj1.html#data-source",
    "href": "tabs/miniproj1.html#data-source",
    "title": "Mini Project #1",
    "section": "Data Source",
    "text": "Data Source"
  },
  {
    "objectID": "tabs/miniproj1.html#joining-with-polygons",
    "href": "tabs/miniproj1.html#joining-with-polygons",
    "title": "Mini Project #1",
    "section": "Joining with Polygons",
    "text": "Joining with Polygons\n\nforests_static &lt;- forests |&gt;\n  mutate(state = str_to_lower(state)) |&gt;\n  right_join(us_states, by = c(\"state\" = \"region\")) \n\n\nfrogs_static &lt;- frogs |&gt;\n  mutate(state = str_to_lower(state)) |&gt;\n  right_join(us_states, by = c(\"state\" = \"region\"))"
  },
  {
    "objectID": "tabs/miniproj1.html#static-mapping",
    "href": "tabs/miniproj1.html#static-mapping",
    "title": "Mini Project #1",
    "section": "Static Mapping",
    "text": "Static Mapping\n\nforests_static |&gt;\n  ggplot(mapping = aes(x = long, y = lat, group = group)) + \n  geom_polygon(aes(fill = forest_cover), color = \"black\", linewidth = 0.2) + \n  labs(fill = \"% Forest Coverage\", title = \"Percent of Forest Coverage in each US State\", x = \"Longitude\", y = \"Latitude\", caption = \"Data Source: USDA Forest Service FIA Annual Report\") +\n  coord_map() +\n  scale_fill_viridis(option = \"viridis\", direction = -1) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nalt text: This is a choropleth map of the United States that is looking a the percentage of land area that is covered by forest in each state. The x-axis is the longitude values of the United States which contain values -120 - -80. The y-axis the latitude values of the United States which contain values 25-50. This map is colored by the percentage forest covereage with the most coverage being a dark purple while the least coverage is a bright yellow. From this map we can see that states in the East have a higher percentage of forest coverage while states in the middle have a much lower percent forest coverage, then the west coast has a medium amount of forest coverage.\n\nfrogs_static |&gt;\n  ggplot(mapping = aes(x = long, y = lat, group = group)) + \n  geom_polygon(aes(fill = frog), color = \"black\", linewidth = 0.2) + \n  labs(fill = \"Frog Common Name\", title = \"Most Observed Threatened Frog in Each State\", x = \"Longitude\", y = \"Latitude\", caption = \"Data Source: https://www.inaturalist.org/observations?place_id=1&subview=map&taxon_id=25473&threatened\") +\n  scale_fill_manual(values = c(\"#800000\", \n                               \"#9A6324\", \n                               \"#808000\", \n                               \"#469990\", \n                               \"#000075\", \n                               \"#000000\", \n                               \"#e6194B\", \n                               \"#f58231\", \n                               \"#ffe119\", \n                               \"#bfef45\", \n                               \"#3cb44b\", \n                               \"#42d4f4\", \n                               \"#4363d8\",\n                               \"#911eb4\", \n                               \"#f032e6\", \n                               \"#fabed4\", \n                               \"#ffd8b1\",\n                               \"#fffac8\",\n                               \"#aaffc3\")) +\n  coord_map() +\n  theme_minimal()"
  },
  {
    "objectID": "tabs/miniproj1.html#joining-for-interactive-polygons",
    "href": "tabs/miniproj1.html#joining-for-interactive-polygons",
    "title": "Mini Project #1",
    "section": "Joining for Interactive Polygons",
    "text": "Joining for Interactive Polygons\n\nstates &lt;- states |&gt;\n  filter(!(name %in% c(\"Alaska\", \"Hawaii\", \"Puerto Rico\"))) |&gt;\n  select(\"name\", \"geometry\")\n\nfrogs_interactive &lt;- frogs |&gt;\n  right_join(states, by = c(\"state\" = \"name\"))\n\n\nforest_interactive &lt;- forests |&gt;\n  right_join(states, by = c(\"state\" = \"name\"))"
  },
  {
    "objectID": "tabs/miniproj1.html#interactive-mapping",
    "href": "tabs/miniproj1.html#interactive-mapping",
    "title": "Mini Project #1",
    "section": "Interactive Mapping",
    "text": "Interactive Mapping\n\nforest_sf &lt;- st_as_sf(forest_interactive) |&gt;\n  mutate(forest_cover = trunc(forest_cover))\n\npal &lt;- colorNumeric(\"Greens\", domain = forest_sf$forest_cover)\n\nforest_sf &lt;- forest_sf |&gt;\n  mutate(labels = str_c(state, \": \", forest_cover, \"% forest cover\"))\n\nlabels &lt;- lapply(forest_sf$labels, HTML)\nleaflet(forest_sf) |&gt;\n  setView(-96, 37.8, 4) |&gt;\n  addProviderTiles(\"Esri.WorldTopoMap\") |&gt;\n  addPolygons(\n    fillColor = ~pal(forest_cover),\n    weight = 2,\n    opacity = 1,\n    color = \"black\",\n    fillOpacity = 0.6,\n    highlightOptions = highlightOptions(\n      weight = 5,\n      color = \"pink\",\n      fillOpacity = 0.7,\n      bringToFront = TRUE),\n    label = labels,\n    labelOptions = labelOptions(\n      style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n      textsize = \"12px\",\n      direction = \"auto\")) |&gt;\n  addLegend(pal = pal, title = \"% Forest Coverage\", values = ~forest_cover, opacity = 0.7, position = \"bottomright\") |&gt;\n  addScaleBar(position = \"bottomleft\") |&gt;\n  addPopups(-95, 50, \"Percentage of Forest Cover in Each State\",\n              options = popupOptions(closeOnClick = FALSE))\n\n\n\n\n\n\nfrog_sf &lt;- st_as_sf(frogs_interactive) \npal &lt;- colorFactor(c(\"#800000\", \n                               \"#9A6324\", \n                               \"#808000\", \n                               \"#469990\", \n                               \"#000075\", \n                               \"#000000\", \n                               \"#e6194B\", \n                               \"#f58231\", \n                               \"#ffe119\", \n                               \"#bfef45\", \n                               \"#3cb44b\", \n                               \"#42d4f4\", \n                               \"#4363d8\",\n                               \"#911eb4\", \n                               \"#f032e6\", \n                               \"#fabed4\", \n                               \"#ffd8b1\",\n                               \"#fffac8\",\n                               \"#aaffc3\"), domain = frog_sf$frog)\n\nfrog_sf &lt;- frog_sf |&gt;\n  mutate(labels = str_c(\"The \", frog, \" is the most observed threatened frog in \", state))\n\nlabels &lt;- lapply(frog_sf$labels, HTML)\n\nleaflet(frog_sf) |&gt;\n  setView(-96, 37.8, 4) |&gt;\n  addProviderTiles(\"Esri.WorldTopoMap\") |&gt;\n  addPolygons(\n    fillColor = ~pal(frog),\n    weight = 2,\n    opacity = 1,\n    color = \"black\",\n    fillOpacity = 0.7,\n    highlightOptions = highlightOptions(\n      weight = 5,\n      color = \"pink\",\n      fillOpacity = 0.7,\n      bringToFront = TRUE),\n    label = labels,\n    labelOptions = labelOptions(\n      style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n      textsize = \"12px\",\n      direction = \"auto\")) |&gt;\n  addLegend(pal = pal, title = \"Frogs Observed\", values = ~frog, opacity = 0.7, position = \"bottomright\") |&gt;\n  addScaleBar(position = \"bottomleft\")"
  },
  {
    "objectID": "tabs/mp4.html",
    "href": "tabs/mp4.html",
    "title": "Mini Project #4",
    "section": "",
    "text": "Introduction\nOne of my favorite bands is called Illuminati Hotties, what I love about them is that all the songs are very different and unique. The main artist is named Sarah Tudzin and in her professional life she is a music producer for many much more popular artists. She also writes and produces her own music and what I think is really cool about it is she just has fun making a bunch of cool and unique sounds, that aren’t dictated by someone else.\nSome of my friends and I went to a concert for another artist called Pom Pom Squad almost 4 years ago at this point where we were first introduced to her and have been hooked ever since, one of the things we always talk about is the uniqueness of her music and the interesting and sometimes slightly disturbing lyrics she uses in her songs. This led me to wanting to do a text analysis of her song lyrics.\n\n\n\nData!\nThere was not a data set of her song lyrics as she is not a very famous artist so i made the maybe silly decision to scrape all the lyrics off the web myself and make my own data set. I did all of this in a document called MP4_cleaning.qmd because it was a lot of code that was not important to the actual project results, it is however linked in my github and on this website page.\nWhat I did was used the web page scraping functions that we made in class to make a similar function that I could input the names of the songs into. I first tried to do all the songs at once but was running into issues with my IP address getting blocked from requesting too much data so I had to break down the songs into smaller requests and I made 10 individual csv files that I then bind_row() into one full data set. This however was only the names of the songs and the lyrics and I wanted an album name which was a little more complicated because the website I used to get the lyrics did not have the album name on the page that the song lyrics were on. So I just did a bunch of if else statements to add the new column. This definitely was not the most efficient method of doing this but its what I did because it was more familiar for a part of the project that was completely unnecessary.\n\n\n\n\n\nSong\nword\nalbum\n\n\n\n\n(You’re Better) Than Ever\nall\nKiss Yr Frenemies\n\n\n(You’re Better) Than Ever\nmy\nKiss Yr Frenemies\n\n\n(You’re Better) Than Ever\nfavorite\nKiss Yr Frenemies\n\n\n(You’re Better) Than Ever\nsocks\nKiss Yr Frenemies\n\n\n(You’re Better) Than Ever\nare\nKiss Yr Frenemies\n\n\n(You’re Better) Than Ever\ngetting\nKiss Yr Frenemies\n\n\n\n\n\nThis is what the data set looks like after I read it into this document and did some final cleaning!\n\nIlluminati Hotties have 5 albums and a couple singles that I am analyzing together as one “album”.\n\n\n\n\n\nLet Me Do One More\n\n\n\n\n\n\nKiss Yr Frenemies\n\n\n\n\n\n\nFree I.H: This is Not the One You’ve Been Waiting For\n\n\n\n\n\n\nNickel on the Fountain Floor\n\n\n\n\n\n\nPower\n\n\n\n\n\n\n\nQuestions\nSome things I want to explore with in this data set are:\n\nMost common words in general, in each song and in each album\nSentient analysis of each album\nNetwork Graph and Correlation\n\n\n\n\nWord Counts\nI first wanted to just look at the most common word in all of her songs in general and found what was expected, words like “I”, “you” and “the” were the most commonly used words.\n\n\n\nMost Common Words for All Songs\n\n\nalbum\nword\nn\n\n\n\n\nPower\ni\n121\n\n\nlet me do one more\ni\n113\n\n\nKiss Yr Frenemies\ni\n100\n\n\nSingle\ni\n70\n\n\nFREE I.H: This Is Not the One You’ve Been Waiting For\nyou\n59\n\n\nNickel on the Fountain Floor\nyou\n17\n\n\n\n\n\n\n\nTo look at just the most common useful words I anti_joined my data set with the set of of smart stop words. Also some of the most common words are not full words and are sounds as words, so I filtered them out using str functions and then looked at the most common words in each album again.\n\n\n\nMost Common Smart Word for Each Album\n\n\nalbum\nword\nn\n\n\n\n\nFREE I.H: This Is Not the One You’ve Been Waiting For\ncontent\n17\n\n\nKiss Yr Frenemies\ntime\n15\n\n\nNickel on the Fountain Floor\n777\n7\n\n\nPower\nlove\n36\n\n\nSingle\nmiss\n11\n\n\nlet me do one more\nwanna\n23\n\n\n\n\n\n\n\n\n\n\nMost Common Word for Each Song\n\n\nSong\nword\nn\n\n\n\n\nYSL\nplay\n20\n\n\ncontent//bedtime\ncontent\n17\n\n\nI Would Like, Still Love You\nlove\n16\n\n\nMMMOOOAAAAAYAYA\nyeah\n16\n\n\nfreequent letdown\nletting\n16\n\n\nu v v p\nhide\n16\n\n\nJoni: LA's No. 1 Health Goth\nbet\n15\n\n\nfree ppls\nfree\n14\n\n\nPatience\ntime\n13\n\n\nWATTBL\ntime\n13\n\n\n(You're Better) Than Ever\nahh\n12\n\n\nSleeping In\nsleeping\n12\n\n\nb yr own b\nfine\n12\n\n\nCheap Shoes\nwear\n10\n\n\nFalling In Love With Somebody Better\nlove\n10\n\n\nI Wanna Keep Yr Dog\ndog\n10\n\n\nYou Are Not Who You Were\nhand\n10\n\n\nsuperiority complex (big noise)\nreal\n10\n\n\nPressed 2 Death\nbad\n9\n\n\nPower\npower\n8\n\n\nTruck\ngive\n8\n\n\n777\n777\n7\n\n\nDecember\ndecember\n7\n\n\nKickflip\nday\n6\n\n\nPool Hopping\nhoppin\n6\n\n\nShape Of My Hands\nthinking\n6\n\n\nThe L\nlove\n6\n\n\nThe Sway\nleaning\n6\n\n\nWreck My Life\nlife\n6\n\n\nboi\nboi\n6\n\n\nDeclutter\nanymore\n5\n\n\nPaying Off The Happiness\npaying\n5\n\n\nwill i get cancelled\nman\n5\n\n\nCuff\ncuff\n4\n\n\nEverything Changes\nlose\n4\n\n\nProtector\nprotector\n4\n\n\nThe Rules\nread\n4\n\n\nThreatening Each Other re: Capitalism\nahh\n4\n\n\nThrow (Life Raft)\nback\n4\n\n\nppl plzr\nbrand\n4\n\n\nFor Cheez (My Friend, Not The Food)\neverything's\n3\n\n\nKiss Yr Frenemies\nwanted\n3\n\n\nKnead\nknead\n3\n\n\nRot\nball\n3\n\n\nSandwich Sharer\nback\n3\n\n\nWhat's the Fuzz\nblinder\n3\n\n\nCan't Be Still\nmoving\n2\n\n\nDidn't\nunenthused\n2\n\n\nGrowth\npretend\n2\n\n\nK - HOT AM 818\nhot\n2\n\n\nToasting\nbiting\n2\n\n\nfree dumb\nfucking\n2\n\n\nmelatonezone\nbarely\n2\n\n\nreasons 2 live\ngood\n2\n\n\n\n\n\n\n\nGraphs to visualize the most common words!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentiment Analysis\nI am really curious about the sentiment analysis of her songs because they lyrics are seemingly random and make not a lot of sense on their own. Also compared to the vibe of the song they sentiment seems to be all over the place. Something I would love to do in the future is add variables that relate to the “vibe” of the song similar to the Spotify data that we have used, there is an energy variable and a couple others that would be interesting to look at compared to the actual text sentiment analysis.\n\n\n\nEmotion of Each Album\n\n\nalbum\nsentiment\nn\n\n\n\n\nFREE I.H: This Is Not the One You’ve Been Waiting For\ntrust\n56\n\n\nKiss Yr Frenemies\nanticipation\n63\n\n\nNickel on the Fountain Floor\nsadness\n15\n\n\nPower\njoy\n59\n\n\nSingle\nanticipation\n33\n\n\nlet me do one more\nfear\n48\n\n\n\n\n\n\n\n\nSentiment Score of Each Album\n\n\nalbum\nvalue\nn\n\n\n\n\nFREE I.H: This Is Not the One You’ve Been Waiting For\n1\n37\n\n\nKiss Yr Frenemies\n2\n32\n\n\nNickel on the Fountain Floor\n-2\n8\n\n\nPower\n3\n44\n\n\nSingle\n-2\n28\n\n\nlet me do one more\n-1\n31\n\n\n\n\n\n\n\n\nPositive vs. Negative Sentiment of Each Album\n\n\nalbum\nsentiment\nn\n\n\n\n\nFREE I.H: This Is Not the One You’ve Been Waiting For\npositive\n85\n\n\nKiss Yr Frenemies\nnegative\n61\n\n\nNickel on the Fountain Floor\nnegative\n16\n\n\nPower\nnegative\n111\n\n\nSingle\nnegative\n59\n\n\nlet me do one more\nnegative\n84\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCorrelations\nI also wanted to look at the correlations between some of the most common words in the songs.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFun Fact!!\nIn the song “Pool Hopping” the first verse goes:\nIn every life there is a bell One rounded curve of time or tell I’m on the left half looking Over, over, over, uh-huh\nReferencing being on the left side of a a bell curve! That’s statistical and semi-relevant!"
  },
  {
    "objectID": "CS263Project/tabs/explore.html#what-does-remote-sensing-actually-look-like",
    "href": "CS263Project/tabs/explore.html#what-does-remote-sensing-actually-look-like",
    "title": "Explore",
    "section": "What does Remote Sensing Actually Look Like?",
    "text": "What does Remote Sensing Actually Look Like?\n\nThis is an example of what an image generated from remote sensing algorithms looks like. It is highlighting the areas in which large harmful algal blooms are present in Lake Erie. In this specific example we can see the migration of these algal blooms over time."
  },
  {
    "objectID": "CS263Project/tabs/remotesensing.html",
    "href": "CS263Project/tabs/remotesensing.html",
    "title": "Remote Sensing",
    "section": "",
    "text": "This first app is a program I made that takes the input of an image that the user can upload, then it makes the image into a raster and averages out the colors in the image into a specified number of groups. The output of this program can detect buildings and trees in images which is similar to what remote sensing can do. This however is a much more manual process then what machine learning in remote sensing can do.\n\n\nThis is package that is accessible in R, called “osmdata” that detects specific things in a map in a specified location. It can detect buildings, roads, water, forests and many other things."
  },
  {
    "objectID": "CS263Project/about.html",
    "href": "CS263Project/about.html",
    "title": "Common Questions",
    "section": "",
    "text": "LiDAR: Light Detection and Ranging, is a method of remote sensing that uses light from pulsed lasers to measure the distances pulsed to get an accurate 3-D readings of the land.\n\n\n\nMODIS: Moderate Resolution Imaging Spectroradiometer, is an instrument on the Terra and Aqua Satellites that scan the Earth’s surface as the satellites orbit. MODIS views the entire Earth every 1-2 days.\n\nInSAR: Interferometric Synthetic Aperture Radar, is imaging that maps ground deformations. InSAR uses radar imaging that penetrates cloud and weather coverage to get accurate readings of the Earth’s surface.\n\nLandsat: The Landsat Satellite Program is a satellite that is constantly acquiring data, from space based imaging of moderate land monitoring. It captures multi-spectral images of the land surface.\n\nSentinel-2: is a Europe based satellite imagery program that uses 2 satellites in orbit for multi-spectral imaging of the land and vegetation.\n\nDrones: UAV Remote Sensing is the use of unmanned aerial vehicles equipped with sensors that are constantly scanning a specific area of the Earth’s surface when they are in the air. These UAV’s can be equipped with LiDAR sensors, MODIS sensors, InSAR sensors and many others. They are alternative to satellite imaging."
  },
  {
    "objectID": "CS263Project/about.html#types-of-remote-sensing",
    "href": "CS263Project/about.html#types-of-remote-sensing",
    "title": "Common Questions",
    "section": "",
    "text": "LiDAR: Light Detection and Ranging, is a method of remote sensing that uses light from pulsed lasers to measure the distances pulsed to get an accurate 3-D readings of the land.\n\n\n\nMODIS: Moderate Resolution Imaging Spectroradiometer, is an instrument on the Terra and Aqua Satellites that scan the Earth’s surface as the satellites orbit. MODIS views the entire Earth every 1-2 days.\n\nInSAR: Interferometric Synthetic Aperture Radar, is imaging that maps ground deformations. InSAR uses radar imaging that penetrates cloud and weather coverage to get accurate readings of the Earth’s surface.\n\nLandsat: The Landsat Satellite Program is a satellite that is constantly acquiring data, from space based imaging of moderate land monitoring. It captures multi-spectral images of the land surface.\n\nSentinel-2: is a Europe based satellite imagery program that uses 2 satellites in orbit for multi-spectral imaging of the land and vegetation.\n\nDrones: UAV Remote Sensing is the use of unmanned aerial vehicles equipped with sensors that are constantly scanning a specific area of the Earth’s surface when they are in the air. These UAV’s can be equipped with LiDAR sensors, MODIS sensors, InSAR sensors and many others. They are alternative to satellite imaging."
  },
  {
    "objectID": "CS263Project/about.html#uses-of-artificial-intelligence-in-remote-sensing",
    "href": "CS263Project/about.html#uses-of-artificial-intelligence-in-remote-sensing",
    "title": "Common Questions",
    "section": "Uses of Artificial Intelligence in Remote Sensing",
    "text": "Uses of Artificial Intelligence in Remote Sensing\n\nWhat is Image Classification?\nFrom viso.ai:\n“A computer analyzes an image in the form of pixels. It does it by considering the image as an array of matrices, with the size of the matrix dependent on the image resolution. Put simply, image classification in a computer’s view is the analysis of this statistical data using algorithms. In digital image processing, image classification is done by automatically grouping pixels into specified categories, so-called “classes.”\n\n\nHow does Object Detection in AI work?\nFrom Daten and Wissen:\n“AI identifies objects in images by looking for visual features that distinguish one object from another. These could be edges, textures, or shapes that appear in the image. Through machine learning, AI becomes proficient at recognizing these features, even in unfamiliar settings. It’s similar to how humans learn to recognize objects: through repeated exposure and pattern recognition. The more data the AI gets, the better it becomes at identifying objects, even in challenging environments like low light or busy scenes.”\n\n\nHow does AI do Pattern Recognition?\nFrom viso.ai:\n“AI pattern recognition using neural networks is currently the most popular method for pattern detection. Neural networks are based on parallel subunits referred to as neurons that simulate human decision-making. They can be viewed as massively parallel computing systems consisting of a huge number of simple processors with many interconnections (Neurons).\nThe most popular and successful form of machine learning using neural networks is deep learning, which applies deep convolutional neural networks (CNN) to solve classification tasks.\nToday, neural network pattern recognition has the edge over other methods because it can change the weights repeatedly on iteration patterns. In recent years, deep learning has proven to be the most successful method to solve recognition tasks. For more information and detailed descriptions of what neural networks are all about, we recommend you read our guide about Machine Learning and Deep Learning.”\n\n\nHow does AI achieve Feature Extraction?\nFrom IBM:\n“First, the model takes in input data, then the feature extractor transforms the data into a numerical representation that can be used to compute the dimensionality reduction methods for feature extraction. These representations are stored in feature vectors for the model to perform algorithms for data reduction.”\n\n\nWhat is Data Fusion?\nFrom Windward:\n“Here’s how data fusion happens:\n\nData acquisition and validation: data is continuously collected from various sources and standardized for analysis. Before moving forward, it is validated to remove inaccuracies, and redundant or erroneous information.\nFeasibility and assignment: the validated data is evaluated to ensure it reflects realistic behavior patterns, after which it is assigned to the most appropriate entities, using advanced matching techniques.\nConflict resolution and refinement: in cases of conflicting data assignments, a scoring mechanism resolves any ambiguities. The data is then further refined to maintain the accuracy and integrity of entity paths.\nData optimization: the final step involves streamlining the dataset, retaining only the most relevant information to ensure efficient processing in downstream applications.”"
  }
]